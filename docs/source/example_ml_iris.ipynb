{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T13:44:39.449161Z",
     "start_time": "2019-12-04T13:44:39.443285Z"
    }
   },
   "source": [
    "<style>\n",
    "pre {\n",
    " white-space: pre-wrap !important;\n",
    "}\n",
    ".table-striped > tbody > tr:nth-of-type(odd) {\n",
    "    background-color: #f9f9f9;\n",
    "}\n",
    ".table-striped > tbody > tr:nth-of-type(even) {\n",
    "    background-color: white;\n",
    "}\n",
    ".table-striped td, .table-striped th, .table-striped tr {\n",
    "    border: 1px solid black;\n",
    "    border-collapse: collapse;\n",
    "    margin: 1em 2em;\n",
    "}\n",
    ".rendered_html td, .rendered_html th {\n",
    "    text-align: left;\n",
    "    vertical-align: middle;\n",
    "    padding: 4px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning (basic): the Titanic dataset\n",
    "\n",
    "While `vaex.ml` does not yet implement predictive models, we provide wrappers to powerful libraries (e.g. [Scikit-learn](https://scikit-learn.org/), [xgboost](https://xgboost.readthedocs.io/)) and make them work efficiently with `vaex`. `vaex.ml` does implement a variety of standard data transformers (e.g. PCA, numerical scalers, categorical encoders) and a very efficient KMeans algorithm that take full advantage of `vaex`.\n",
    "\n",
    "The following is a simple example on use of `vaex.ml`. We will be using the well known Iris dataset, and we will use it to build a model which distinguishes between the three Irish species ([Iris setosa](https://en.wikipedia.org/wiki/Iris_setosa), [Iris virginica](https://en.wikipedia.org/wiki/Iris_virginica) and [Iris versicolor](https://en.wikipedia.org/wiki/Iris_versicolor)).\n",
    "\n",
    "Lets start by importing the common libraries, load and inspect the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vaex\n",
    "import vaex.ml\n",
    "\n",
    "import pylab as plt\n",
    "\n",
    "\n",
    "df = vaex.ml.datasets.load_iris()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into _train_ and _test_ steps should be done immediately, before any manipulation is done on the data. `vaex.ml` contains a `train_test_split` method which creates shallow copies of the main DataFrame, meaning that no extra memory is used when defining train and test sets. Note that the `train_test_split` method does an ordered split of the main DataFrame to create the two sets. In some cases, one may need to shuffle the data.\n",
    "\n",
    "If shuffling is required, we recommend the following:\n",
    "```\n",
    "df.export(\"shuffled\", shuffle=True)\n",
    "df = vaex.open(\"shuffled.hdf5)\n",
    "df_train, df_test = df.ml.train_test_split(test_size=0.2)\n",
    "```\n",
    "\n",
    "In the present scenario, the dataset is already shuffled, so we can simply do the split right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orderd split in train and test\n",
    "df_train, df_test = df.ml.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is a very simple tutorial, we will just use the columns already provided as features for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_train.column_names[:4]\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T14:06:45.512795Z",
     "start_time": "2019-12-04T14:06:45.510575Z"
    }
   },
   "source": [
    "## PCA\n",
    "\n",
    "The `vaex.ml` module contains several classes for dataset transformations that are commonly used to pre-process data prior to building a model. These include numerical feature scalers, category encoders, and [PCA](https://en.wikipedia.org/wiki/Principal_component_analysis) transformations. We have adopted the [`scikit-learn`](https://scikit-learn.org/stable/) API, meaning that all transformers have the `.fit` and `.transform` methods. \n",
    "\n",
    "Let's use apply a PCA transformation on the training set. There is no need to scale the data beforehand, since the PCA also normalizes the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = vaex.ml.PCA(features=features, n_components=4)\n",
    "df_train = pca.fit_transform(df_train)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of pca `.fit_transform` method is a shallow copy of the DataFrame which contains the resulting columns of the transformation, in this case the PCA components, as virtual columns. This means that the transformed DataFrame takes no memory at all! So while this example is made with only 120 sample, this would work in the same way even for millions or billions of samples.\n",
    "\n",
    "## Gradient boosting trees\n",
    "\n",
    "Now let's train a gradient boosting model. While `vaex.ml` does not currently include this type of models, we support the popular boosted trees libraries [`xgboost`](https://xgboost.readthedocs.io/en/latest/), [`lightgbm`](https://lightgbm.readthedocs.io/en/latest/), and [`catboost`](https://catboost.ai/). In this tutorial we will use the `lightgbm` classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "import vaex.ml.sklearn\n",
    "\n",
    "# Features on which to train the model\n",
    "train_features = df_train.get_column_names(regex='PCA_.*')\n",
    "\n",
    "# Instantiate the LightGBM Classifier\n",
    "booster = lightgbm.sklearn.LGBMClassifier(num_leaves=5, \n",
    "                                          max_depth=5, \n",
    "                                          n_estimators=100,\n",
    "                                          random_state=42)\n",
    "\n",
    "# Make it a vaex transformer (for the automagic pipeline and lazy predictions)\n",
    "model = vaex.ml.sklearn.SKLearnPredictor(features=train_features, model=booster, prediction_name='prediction')\n",
    "\n",
    "# Train and predict\n",
    "model.fit(df=df_train, target='class_')\n",
    "df_train = model.transform(df=df_train)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T14:40:52.347957Z",
     "start_time": "2019-12-04T14:40:52.345452Z"
    }
   },
   "source": [
    "Notice that after training the model, we use the `.transform` method to obtain a shallow copy of the DataFrame which  contains the prediction of the model, in a form of a virtual column. This makes it easy to evaluate the model, and easily create various diagnostic plots. If required, one can call the `.predict` method, which will result in an in-memory `numpy.array` housing the predictions.\n",
    "\n",
    "## Automatic pipelines\n",
    "\n",
    "Assuming we are happy with the performance of the model, we can continue and apply our transformations and model to the test set. Unlike other libraries, we do not need to explicitly create a pipeline here in order to propagate the transformations. In fact, with `vaex` and `vaex.ml`, a pipeline is automatically being created as one is doing the exploration of the data. Each `vaex` DataFrame contains a _state_, which is a (serializable) object containing information of all transformations applied to the DataFrame (filtering, creation of new virtual columns, transformations).\n",
    "\n",
    "Recall that the outputs of both the PCA transformation and the boosted model were in fact virtual columns, and thus are stored in the state of `df_train`. All we need to do, is to apply this state to another similar DataFrame (e.g. the test set), and all the changes will be propagated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = df_train.state_get()\n",
    "df_test.state_set(state)\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production\n",
    "\n",
    "Now `df_test` contains all the transformations we applied on the training set (`df_train`), including the model prediction. The transfer of state from one DataFrame to another can be extremely valuable for putting models in production.\n",
    "\n",
    "## Performance\n",
    "Finally, let's check the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(y_true=df_test.class_.values, y_pred=df_test.prediction.values)\n",
    "acc *= 100.\n",
    "print(f'Test set accuracy: {acc}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T15:03:26.881910Z",
     "start_time": "2019-12-04T15:03:26.872187Z"
    }
   },
   "source": [
    "The model get perfect accuracy of 100%. This is not surprising as this problem is rather easy: doing a PCA transformation on the features nicely separates the 3 flower species. Plotting the first two PCA axes, and colouring the samples according to their class already shows an almost perfect separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "df_test.scatter(df_test.PCA_0, df_test.PCA_1, c_expr=df_test.class_, s=50)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
